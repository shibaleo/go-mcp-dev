# DAY7 作業ログ

## 2026-01-16: リスク分析レビュー

### 前提条件（更新）

| 項目 | 値 | 備考 |
|------|-----|------|
| **総ユーザー数** | 10,000 | 目標値 |
| **MAU** | 1,000 | 月間アクティブユーザー（10%） |
| **インフラ構成** | Koyeb nano + Fly.io nano | 並行稼働・ロードバランシング |
| **Phase 1プラン** | Unlimited | rate_limit=-1, quota_limit=-1 |

### スケール変更によるリスク再評価

1,000 MAU規模では以下のリスクの優先度が上がる:

| リスク | 旧評価（5-10人） | 新評価（1,000 MAU） | 理由 |
|--------|-----------------|-------------------|------|
| Rate Limitバイパス | Phase 2 | **要検討** | 同時アクセス増でバイパス確率上昇 |
| キャッシュ不整合 | 許容 | **中** | ユーザー体験のばらつきが目立つ |
| KV書き込み枠超過 | 問題なし | **要監視** | 1,000 MAU × 平均req数で枠に接近 |
| DB障害時フォールバック | 推奨 | **高** | 影響範囲が1,000人に拡大 |

**結論**: Koyeb nano + Fly.io nano並行稼働でインフラキャパシティは対応可能。ただしRate Limitの共有ストレージ（Redis/KV）導入はPhase 1後半またはPhase 2初期での対応を推奨。

### スケーリング計画: 無料枠崩壊ポイント

**設計方針**: スケール時にアーキテクチャ変更不要、課金のみで対応可能にする

| スケール | 超過サービス | 対応 | 追加コスト |
|----------|-------------|------|-----------|
| **500 MAU（5,000ユーザー）** | Supabase DB転送量 | Pro プラン | $25/月 |
| **1,000 MAU（10,000ユーザー）** | Koyeb/Fly.io RAM | 有料プラン | +$3-5/月/台 |
| **3,000+ MAU** | 上記 + Vercel等 | - | ~$50-75/月 |

**計算前提**:
- 1ユーザーあたり平均 10 req/日
- **Burst超過率: 0.1%**（1,000リクエストに1回程度）
- Cloudflare KV無料枠: 1,000 write/日
- Supabase無料枠: 500MB, 2GB転送/月

**Burst超過率の根拠**:
- Burst制限（5 req/s）は瞬間的なリクエスト集中を防ぐ
- 通常利用ではBurst超過は稀（ユーザーが意図的にスパムしない限り発生しない）
- 0.1%は保守的な見積もり

**KV書き込み計算（修正版）**:
```
1,000 MAU × 10 req/日 = 10,000 req/日
Burst超過 = 10,000 × 0.1% = 10 write/日
→ 無料枠 1,000 write/日 に対して余裕あり
```

**最初に崩れる無料枠**: Supabase DB（転送量 or ストレージ、500-1,000 MAU時点）

### 無料枠崩壊の詳細順序

| 順位 | サービス | 無料枠 | 崩壊タイミング | 有料化コスト |
|------|----------|--------|---------------|-------------|
| 1 | Supabase DB | 500MB, 2GB転送 | 500-1,000 MAU | $25/月 |
| 2 | Koyeb/Fly.io RAM | 各256MB | 1,000-2,000 MAU | $3-5/月/台 |
| 3 | Vercel 帯域 | 100GB/月 | 5,000+ MAU | $20/月 |
| 4 | Cloudflare Workers | 10万req/日 | 10,000+ MAU | $5/月 |
| 5 | Cloudflare KV 書き込み | 1,000/日 | 10,000+ MAU※ | $5/月 |
| 6 | Supabase Auth | 50,000 MAU | 50,000 MAU | 込み |

※ Burst超過率0.1%の場合、10,000 MAUでも100 write/日程度

### コスト推移

| MAU | 月額コスト | 内訳 |
|-----|-----------|------|
| ~500 | $0 | 全て無料枠内 |
| 500-1,000 | $25 | Supabase Pro |
| 1,000-3,000 | $30-35 | + RAM増強 |
| 3,000-10,000 | $50-75 | + Vercel/追加リソース |

### 構成の整理

```
Cloudflare Workers (LB)
    ├─ Koyeb Nano (アクティブ)
    └─ Fly.io Nano (アクティブ)
```

- 両台が常時リクエストを処理（ホットスタンバイではなくロードバランス）
- 1台が落ちても継続稼働
- ベンダー分散によるリスク軽減

### 注意点

| 課題 | 対策 |
|------|------|
| セッション/キャッシュ不整合 | Sieveキャッシュは各台独立でOK（TTLで収束） |
| ヘルスチェック | Cloudflare Workersで実装 |
| デプロイ同期 | 両方に同時デプロイするCI/CD |

### Supabase DB I/O 元

| アクセス元 | 操作 | 対象 | 頻度 |
|-----------|------|------|------|
| MCPサーバー (Tool Sieve) | R | 権限チェック | 毎req（キャッシュ5分） |
| MCPサーバー (UsageController) | R/W | Quota/Credit | 毎req |
| Token Broker (Edge Function) | R/W | oauth_tokens (Vault経由) | 外部API呼出時 |
| 管理UI (Vercel) | CRUD | users, roles, permissions | 低頻度 |

**最大負荷元**: MCPサーバーからの権限・使用量チェック

**対策**: 権限チェックはローカルキャッシュ + Supabase Realtimeでイベント駆動無効化 → [dsn-cache-share.md](./dsn-cache-share.md)

---

### 背景

使用量制御（Burst, Rate Limit, Quota, Credit）のアーキテクチャ設計完了後、以下の観点で未カバーリスクを洗い出した:

- 安定運用
- レジリエンス
- 放置運用
- 継続開発
- セキュリティ

---

## リスク分析結果

### 評価サマリー

| 観点 | 評価 | 主なカバー漏れ |
|------|------|----------------|
| **安定運用** | 不十分 | マルチインスタンスでRate Limit分散、DB障害時のキャッシュ戦略 |
| **レジリエンス** | 不十分 | Cloudflare障害時の通知機構、Webhook冪等性 |
| **放置運用** | 未カバー | アラート通知先未定義、容量計画なし、自動ロールバックなし |
| **継続開発** | 未カバー | DBマイグレーション管理なし、ユーザー初期化の自動化不明確 |
| **セキュリティ** | 未カバー | JWT revocationなし、設定ミスのフェイルセーフなし |

---

## 詳細リスク一覧

### 1. 安定運用

#### 1-1. マルチインスタンスでRate Limitバイパス可能【高】

**現状**: Rate LimiterはOrigin側のメモリに保存

**リスク**:
```
シナリオ: Rate Limitのバイパス
  1. ユーザーA: 1分間に30req送信（Free枠）
  2. Koyeb側では拒否（counter=30に達した）
  3. しかしFly.io側にリクエストが到達すると
     Fly.io側のcounterはリセット状態
  4. Fly.ioで追加30req許可される（合計60req）

  → Rate Limitが機能しない
```

**対策案**:
- A: Rate LimitをWorker側のみに統一（KV使用）
- B: Redis等の共有ストレージ導入
- C: Phase 1は「Unlimited」なので影響なし、Phase 2で対応

---

#### 1-2. DB障害時のキャッシュフォールバック戦略なし【高】

**現状**: PermissionCache TTL 5分、DB障害時の挙動未定義

**リスク**:
```
シナリオ: Supabase障害（全リージョン）
  1. MCPサーバー: SELECT権限キャッシュ → timeout
  2. ヘルスチェック失敗
  3. 両インスタンスunhealthy
  4. ユーザーは完全にアクセス不可
```

**対策案**:
- A: Stale-While-Revalidate戦略（古いキャッシュを使い続ける）
- B: Read-through cache with circuit breaker
- C: ローカルファイルにバックアップ

---

#### 1-3. 権限キャッシュの不整合（マルチインスタンス）【中】

**現状**: 各インスタンスが独立したキャッシュを持つ

**リスク**:
```
シナリオ: 権限レイシー
  1. 権限変更: Notion無効化
  2. Koyeb側: キャッシュinvalidate → 新規取得
  3. Fly.io側: TTL 4分58秒 → 古い情報（Notion有効）
  4. 同一ユーザーがインスタンス間で異なる結果を得る
```

**対策案**:
- A: TTLを短く（1分）
- B: Redis Pub/Subでinvalidate同期
- C: Phase 1規模では許容

---

### 2. レジリエンス

#### 2-1. Cloudflare障害時のフォールバック通知機構なし【中】

**現状**: 直接URL案内で対応と記載、通知方法未定義

**リスク**:
```
シナリオ: Cloudflare障害（2-3時間）
  1. MCPクライアント: APIエラーで動作停止
  2. ユーザー側で直接URL変更が必要
  3. しかし放置運用なので誰も通知しない
  4. 数時間アクセス不可
```

**対策案**:
- A: ステータスページ（Instatus等）で障害通知
- B: Discord/Slackで障害アナウンス自動化
- C: MCPクライアント側にフォールバックURL設定

---

#### 2-2. Stripe Webhook失敗時のリトライ/冪等性【中】

**現状**: Webhook処理のリトライ戦略が不明確

**リスク**:
```
シナリオ: Webhook配信失敗
  1. ユーザーが料金支払い（Stripe側で完結）
  2. Webhook送信失敗（ネットワーク障害）
  3. ユーザーの permissions.subscription_ok = false のまま
  4. ユーザーはお金を払ったが使えない状態
```

**対策案**:
- A: Stripe Webhook リトライを明示的に文書化
- B: Idempotency key導入
- C: Edge FunctionでDB更新失敗時のリトライ実装

---

#### 2-3. KV書き込み枠超過時の対応【低】

**現状**: Cloudflare KV無料枠 1,000 write/日

**リスク**:
```
シナリオ: KV書き込み枠オーバー
  1. 100人が一気にアクセス
  2. 各ユーザーのBurst制限カウントをKVに書き込み
  3. 枠を超えた場合、以降のRate Limitが機能しない
```

**対策案**:
- A: 使用量監視とアラート設定
- B: 有料枠への自動アップグレード設定
- C: Phase 1規模（5-10人）では問題なし

---

### 3. 放置運用

#### 3-1. アラート通知先・受信確認機構なし【高】

**現状**: Grafana Cloudアラート設定あり、通知先未記載

**リスク**:
```
シナリオ: アラート無視
  1. 深夜2時: CPU Warningアラート通知 → メール着信
  2. 朝6時に気づく → 既に6時間経過
  3. アラート疲れで「Warningは無視」という心理状態に
  4. Critical も同様に無視される可能性
```

**対策案**:
- A: Slack/Discord通知設定
- B: Critical のみ通知（Warning は抑制）
- C: オンコール体制（友人ネットワークで分担）

---

#### 3-2. デプロイ失敗時の自動ロールバックなし【中】

**現状**: デプロイ失敗時はGitHub Actions通知 → 手動対応

**リスク**:
```
シナリオ: デプロイ失敗の放置
  1. 22:00: 本番デプロイ実行
  2. 22:05: ヘルスチェック失敗 → CI/CD中断
  3. 06:00: 朝に気づく → 古いバージョンが6時間放置
```

**対策案**:
- A: ヘルスチェック失敗時の自動ロールバック
- B: Canaryデプロイ（Fly.io先行→確認後Koyeb）
- C: 失敗時はCI/CD側でgit revert自動実行

---

#### 3-3. 容量計画・スケーリング戦略なし【低】

**現状**: Phase 1は無料枠、スケール時の対応未定義

**リスク**:
```
シナリオ: 容量超過と予期しない課金
  1. 3ヶ月後: 50人にスケール
  2. Koyeb: メモリ常時80%
  3. Fly.io: 帯域超過 → 課金開始
  4. 気づいた時点で月額$100/月に
```

**対策案**:
- A: 使用量監視ダッシュボード
- B: 閾値アラート（無料枠80%到達時）
- C: Phase 2移行計画を事前に策定

---

### 4. 継続開発

#### 4-1. DBマイグレーション戦略なし【高】

**現状**: Supabaseにテーブル定義あり、マイグレーションツールなし

**リスク**:
```
シナリオ: スキーマ変更による不整合
  1. Phase 2で新機能追加「ユーザー優先度」
  2. migration: ALTER TABLE users ADD COLUMN priority INT
  3. Koyeb: 新版デプロイ → priority カラム参照
  4. Fly.io: まだ旧版 → priority カラムが見えない
  5. SELECT priority FROM users → 500 エラー
```

**対策案**:
- A: golang-migrate導入
- B: Supabase Migrations機能使用
- C: ゼロダウンタイムマイグレーション戦略策定

---

#### 4-2. 新規ユーザー権限初期化の自動化不明確【中】

**現状**: 初期権限設定の実装詳細が未記載

**リスク**:
```
シナリオ: 新規ユーザーが何もできない
  1. ユーザーAが登録
  2. Supabase Auth: id='xxx' で作成
  3. user_tool_permissions: レコードなし（挿入処理なし）
  4. 全ツール拒否される
```

**対策案**:
- A: Supabase Auth Trigger（PostgreSQL関数）
- B: アプリケーション側で初回アクセス時に初期化
- C: 初期権限テーブルのシード処理

---

#### 4-3. APIバージョニング戦略なし【低】

**現状**: 拒否理由の追加等、破壊的変更の対応未定義

**リスク**:
```
シナリオ: クライアント・サーバー版の不一致
  1. MCPサーバー: burst_exceeded 拒否理由追加
  2. 古いMCPクライアント: burst_exceeded を知らない
  3. エラーメッセージ: "Unknown error code"
```

**対策案**:
- A: MCPプロトコルの拡張性に依存（新フィールドは無視される）
- B: バージョンヘッダー導入
- C: Phase 1規模では許容

---

### 5. セキュリティ

#### 5-1. JWT revocation機構なし【中】

**現状**: JWT署名検証のみ、個別無効化機能なし

**リスク**:
```
シナリオ: JWT漏洩時の個別対応不可
  1. ユーザーAが「APIトークンが漏洩した」と報告
  2. 対応: 「パスワードリセットしてください」のみ
  3. しかし漏洩したJWT（有効期限6ヶ月）は有効なまま
```

**対策案**:
- A: JWTブラックリスト（Redis/KV）
- B: JWTの有効期限を短く（1時間）+ リフレッシュトークン
- C: アカウントsuspendで全JWT無効化（現状の対応）

---

#### 5-2. Worker設定ミス検出なし【高】

**現状**: デプロイ後検証にWorker有効化確認なし

**リスク**:
```
シナリオ: Worker設定の無効化によるバイパス
  1. Cloudflare 管理画面: Workers → 誤ってルート削除
  2. API リクエスト: mcp.mcpist.com → オリジン直接到達
  3. X-User-ID ヘッダーなし → auth middleware エラー
  4. しかし、X-User-ID: 任意ユーザー で再試行可能
  5. 権限チェック完全無視
```

**対策案**:
- A: デプロイ後検証にWorker経由のリクエストテスト追加
- B: オリジン側でX-Gateway-Secretを必須に
- C: Terraform管理でWorker設定の変更を検知

---

#### 5-3. シークレットローテーション戦略なし【中】

**現状**: GitHub Secretsで管理、ローテーション方法未定義

**リスク**:
```
シナリオ: GitHub侵害によるシークレット流出
  1. GitHub アカウント乗っ取り
  2. GitHub Secrets: GATEWAY_SECRET 閲覧可能
  3. 攻撃者: GATEWAY_SECRET を使ってWorkerをバイパス
```

**対策案**:
- A: 定期ローテーション（3ヶ月ごと）
- B: GitHub Secrets以外の管理（1Password, Vault等）
- C: 侵害検知時の即座ローテーション手順書

---

#### 5-4. 監査ログがPhase 1スコープ外【低】

**現状**: 明示的にスコープ外、Grafanaログのみ（14日保持）

**リスク**:
- 侵害検知が遅延
- 事後分析が困難

**対策案**:
- A: Phase 2で監査ログ実装
- B: Grafanaログ保持期間延長
- C: Phase 1規模では許容

---

## 優先度付きタスクリスト

### 必須（Phase 1ブロッカー）

| ID | タスク | 理由 |
|----|--------|------|
| P1-1 | アラート通知先設定（Slack/Discord） | 放置運用の大前提 |
| P1-2 | X-Gateway-Secret検証の必須化 | セキュリティの最低ライン |
| P1-3 | DBマイグレーションツール導入 | 継続開発の基盤 |

### 推奨（Phase 1中に対応）

| ID | タスク | 理由 |
|----|--------|------|
| P1-4 | Stripe Webhook冪等性確保 | 課金トラブル防止 |
| P1-5 | キャッシュフォールバック戦略実装 | DB障害時の継続性 |
| P1-6 | デプロイ後Worker検証追加 | 設定ミス検出 |

### 後回し（Phase 2以降）

| ID | タスク | 理由 |
|----|--------|------|
| P2-1 | Rate Limit共有ストレージ化 | Phase 1はUnlimitedで影響なし |
| P2-2 | JWT revocation機構 | suspend対応で代替可能 |
| P2-3 | 監査ログ実装 | Phase 1規模では不要 |
| P2-4 | 容量計画・スケーリング戦略 | スケール後に対応 |
| P2-5 | 自動ロールバック | 手動対応で許容 |

---

## 次のアクション

- [ ] 上記リスクと対策案を確認
- [ ] 優先度の妥当性を検討
- [ ] Phase 1必須タスクをドキュメントに反映

---

## マルチインスタンスでのRate Limit共有問題

### 課題

Koyeb + Fly.io構成でRate Limitをどう共有するか。

### 検討経緯

1. **Redis/Upstash案** → 却下
   - 第三のホスト（Upstash）が必要
   - Koyeb（リージョン制限）とFly.io（東京）の中間にRedisを置く場所が難しい
   - 「スケール戦略は課金のみ。あとからUpstashを追加するとか不可能」

2. **Fly.io一本化案** → 却下
   - ベンダー分散の設計原則に反する

3. **Cloudflare KV案** → インフラ保護には採用、ビジネスロジックには不採用
   - KVは結果整合性（リージョン間で数秒の遅延）
   - グローバルに厳密な一貫性は保証されない

### 結論: リスク種別で分離

| リスク種別 | 厳密性 | 保存先 | 理由 |
|-----------|--------|--------|------|
| **インフラリスク** | 緩くてOK | Cloudflare KV / メモリ | ユーザーへの約束ではない |
| **ビジネスリスク** | 厳密 | Supabase DB | 課金に直結、ユーザー契約 |

### 各制御の分類

| 制御 | リスク種別 | 厳密性 | 保存先 | 理由 |
|------|-----------|--------|--------|------|
| Burst | インフラ | 緩い | Cloudflare KV | オリジン保護、ユーザー契約外 |
| Rate Limit | インフラ | 10%程度 | Supabase DB | 自前リソース消費のみ、外部APIコストなし |
| Quota | ビジネス | 厳密 | Supabase DB | 月間上限、課金に直結 |
| Credit | ビジネス | 厳密 | Supabase DB | 残高管理、超過=損失 |

### Rate Limit共有の再検討: DB同期で10%誤差に

**当初の想定**: メモリのみ → 最悪2倍（30→60 req/min）
**問題**: 2倍は緩すぎる。厳密性は不要だが、10-15%程度の誤差が妥当。

**DB同期が可能な理由**:
```
Rate Limit時間窓 = 1分（60秒）
30 req/min の場合、平均リクエスト間隔 = 2秒

DB同期レイテンシ = 20-50ms
リクエスト間隔（2秒）に対して十分短い

→ DB同期で整合性が取れる
```

**誤差計算**:
```
同時到着確率 = 50ms / 2000ms = 2.5%
誤差期待値 = 30 × 2.5% = 0.75 req/min
最悪ケース = 30 + 数req = 33 req/min程度

→ 10%誤差内に収まる
```

**Burstとの違い**:
| 制御 | 時間窓 | 平均間隔 | DB同期 | 許容誤差 |
|------|--------|----------|--------|----------|
| Burst | 1秒 | 200ms | 不可能（50ms遅延が25%） | 結果整合でOK |
| Rate Limit | 1分 | 2秒 | 可能（50ms遅延が2.5%） | 10-15% |

### Supabase PostgreSQLを毎リクエストで使わない理由

- レイテンシ: 20-50ms（毎リクエストでは遅い）
- 帯域制限: 2GB/月（無料枠）
- 計算: 1,000 MAU × 10 req/日 × 30日 × 1KB = 3GB/月 → 超過

### 最終設計

| 制御 | 実装場所 | 保存先 | 共有 | 許容誤差 |
|------|----------|--------|------|----------|
| Burst | Worker | Cloudflare KV | 結果整合 | 緩くてOK |
| Rate Limit（グローバル） | Worker | Cloudflare KV | 結果整合 | 緩くてOK |
| Rate Limit（ユーザー別） | Origin | **Supabase DB** | DB同期 | **10-15%** |
| Quota | Origin | Supabase DB | ACID保証 | 厳密 |
| Credit | Origin | Supabase DB | ACID保証 | 厳密 |

**Rate Limit（ユーザー別）もDB同期で共有**。時間窓が1分と長いため、DB同期で10%程度の誤差に収められる。

### Rate Limitは「課金対象ではなく抱き合わせオプション」

```
Starterプラン: $9.99/月
  ├─ Quota: 10,000 req/月 ← これがメインの価値（課金対象）
  ├─ Credit: なし
  └─ Rate Limit: 60 req/min ← おまけ（条件緩和の抱き合わせ）

ユーザーが払っているのは「月10,000リクエスト」であって
「60 req/minの保証」ではない。
```

### Rate Limit超過の損失分類

| 超過ケース | 損失の種類 | 損失の大きさ |
|-----------|-----------|-------------|
| Rate Limit 超過 | 自前リソース消費（サーバー負荷増） | 中 |
| Quota 超過 | 外部APIコスト + 契約違反 | 大 |

```
Rate Limit超過の損失:
- 可用性を売りにしているサービスにとって、Rate Limitは自社リソース保護
- 2倍使われる = サーバー負荷が2倍 = 明確な損失
- Burstで5 req/sに抑えられているが、分単位の過負荷は防げない

Quota超過の損失:
- 外部API呼び出しコスト発生（Notion, Google等）
- ユーザーへの契約違反
- 追加課金: 発生する可能性
```

### SaaS Rate Limit 調査結果

各種SaaSのAPI Rate Limitを調査し、MCPistのBurst/Rate Limit値の妥当性を検討。

| サービス | Rate Limit | 単位 | 備考 |
|----------|------------|------|------|
| **Notion** | 3 req/s | per integration | ユーザー参考値 |
| **Fitbit** | 5 req/s | per user | ユーザー参考値 |
| **Airtable** | 5 req/s | per base | 厳格 |
| **Shopify** | 2 req/s | leak rate (REST) | Leaky Bucket方式 |
| **Slack** | 0.83-1 req/s | per method tier | Tier依存、50 req/min |
| **GitHub** | 1.4 req/s | authenticated | 5,000 req/hour |
| **Stripe** | 25 req/s | default | 高め、決済系 |
| **Twilio** | 20 req/s | endpoint依存 | 通信系 |
| **Discord** | 50 req/s | global | Bot向け、緩め |
| **Google Geocoding** | 50 req/s | per project | API種別で大きく異なる |
| **Jira/Confluence** | ポイント制 | 65,000 pts/hour | 複雑な計算 |

**傾向分析**:
- **厳格（1-5 req/s）**: Notion, Fitbit, Airtable, Shopify, Slack, GitHub
- **緩め（20-50 req/s）**: Stripe, Twilio, Discord, Google

**MCPistの特性**:
- AIエージェントからのアクセス（ループ処理で連続リクエスト発生）
- MAU 1,000目標（Koyeb nano + Fly.io nano）
- 1ツール呼び出し = 1リクエスト

**Phase 1 決定値**:
| 制御 | 値 | 理由 |
|------|-----|------|
| Burst | 5 req/s | Notion/Fitbit/Airtable同等、業界標準 |
| Rate Limit | 60 req/min | 1 req/s相当、Slack/GitHubレベル |

**根拠**:
- 5 req/s Burstは「寛大すぎない」業界標準
- 60 req/min（1 req/s）は持続的利用として妥当
- AIエージェントが5ツール連続呼び出し → Burstで吸収
- その後1秒に1回ペースで継続 → Rate Limitで制御

**実装場所**:
- Burst: Worker（Cloudflare KV、1秒窓なので履歴不要・捨ててOK）
- Rate Limit: Origin（Supabase DB、マルチインスタンス共有で10%誤差に収める）

### ビジネス判断: 厳密性 vs 技術的負債

**厳密にしない理由**:
- Redis等の共有ストレージ導入 = 技術的負債 + 運用コスト
- 「スケール時は課金のみで対応」原則に反する（第三のホスト追加）
- DB同期で10-15%程度の誤差に収められる

**判断**: 厳密な保証（Redis）は技術的負債。DB同期で10%程度の誤差に抑えるのが妥当な落とし所。

### 契約上の位置づけ

**Rate Limitは全プランで厳密な保証をしない**。

```
利用規約での表記例:
「Rate Limitは目安であり、サーバー負荷状況により変動する場合があります」

理由:
- マルチインスタンス構成でRate Limitが2倍になる可能性がある
- ユーザーにとっては「得」になるのでクレームにならない
- 厳密な保証をするためのインフラコスト（Redis等）が割に合わない
```

---

## 関連ドキュメント

- [dsn-infrastructure.md](./dsn-infrastructure.md)
- [dsn-load-management.md](./dsn-load-management.md)
- [dsn-subscription.md](./dsn-subscription.md)
- [dsn-deployment.md](./dsn-deployment.md)
- [dsn-permission-system.md](./dsn-permission-system.md)
- [dsn-cache-share.md](./dsn-cache-share.md) - キャッシュ共有設計
- [adr-usage-control-architecture.md](./adr-usage-control-architecture.md)
