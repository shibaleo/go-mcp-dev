# ADR-001: バックエンドLLMを使用しない

作成日: 2026-01-11
ステータス: 採用

---

## コンテキスト

MCPistの設計において、2つのアプローチが検討された：

1. 純粋な計算サーバーとしての振る舞い: MCPistはLLMを持たず、決定論的処理に徹する
2. ユーザーコンテキストによる効率化: バックエンドLLM（Haiku）でDAG計画を生成する

両アプローチは「コンテキスト保護」「オーケストレーター」という点で一致するが、LLM使用の有無で対立していた。

---

## 決定

**純粋な計算サーバーとしての振る舞いを採用する。MCPistはバックエンドLLMを使用しない。**

---

## 理由

### 1. 責任境界の明確化

MCPistがLLMを持つと：
- ツール選択の判断責任がMCPistに移る
- 結果の要約・フィルタリングの判断責任も発生
- 「何を返さないか」の決定権を持つことになる

これはオーケストレーターではなくエージェントになるということ。

### 2. 障害点の増加

- 内部LLMの判断ミスはユーザーのLLMには見えない
- 悪い結果が返ったとき、責任の所在が曖昧になる

### 3. コスト構造の複雑化

- MCPist側でLLM呼び出しコストが発生
- 誰が払うか？という問題が生じる

### 4. 決定論的処理への徹底

MCPistは純粋な計算サーバーとして「決定論的」に徹する。非決定論的処理は全てユーザーLLMに委ねる。

---

## 影響

### 採用する機能

Design-Philosophyで定義された3つの機能：

1. **get_module_schemas**: モジュール名の配列 → ツール定義を返す（動的スキーマ開示）
2. **execute_dag**: ユーザーLLMが生成したDAG → 実行結果を返す（宣言的）
3. **execute_go**: ユーザーLLMが生成したGoスクリプト → 実行結果を返す（命令的）

### 廃止する機能

Context-Efficient-Architectureで提案されていた：

- バックエンドLLM（Haiku）によるDAG計画生成
- output_templateによる要約

### コンテキスト消費について

ユーザーLLMがDAGを生成するため、コンテキスト消費は増加する。これは「責任を明確にするためのコスト」として受け入れる。

> MCPistが解釈する → コンテキスト消費低、責任境界曖昧
> ユーザーLLMが具体化する → コンテキスト消費高、責任境界明確
>
> **MCPistは後者を選択する。**

---

## 代替案

### 案1: バックエンドLLMをオプション提供（不採用）

Plusプラン等でバックエンドLLMを提供する案。責任境界が曖昧になるため不採用。

### 案2: 段階的移行（不採用）

まずバックエンドLLMあり、後で廃止する案。ユーザーが混乱するため不採用。

---

## 関連ドキュメント

- [MCPist-Design-Philosophy.md](MCPist-Design-Philosophy.md) - 採用
- [mcpist-context-efficient-architecture.md](mcpist-context-efficient-architecture.md) - 要更新（ステータス変更）
